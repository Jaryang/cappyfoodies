{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470b60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Note: relevant modules from nltk need to be pre-installed by the code \n",
    "# as follows:\n",
    "# ---------------------------------------------------------------------\n",
    "# import nltk\n",
    "# import ssl\n",
    "# try:\n",
    "    # _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "    # pass\n",
    "# else:\n",
    "    # ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def read_review_json(address, hint = -1):\n",
    "    \"\"\"\n",
    "    Convert json data into Python dict\n",
    "    \n",
    "    Inputs: \n",
    "        address(str): address of the file\n",
    "        hint(int): specify how many bites would be read(-1 means \"read all\")\n",
    "    Outputs: a dict of reviews of the restaurants\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(address) as f:\n",
    "        dta_json = f.readlines(hint)\n",
    "    \n",
    "    return json.loads(dta_json[0])\n",
    "\n",
    "\n",
    "def gene_text_dict(res_info):\n",
    "    \"\"\"\n",
    "    Generate a dict containing comments for each restaurant\n",
    "    \n",
    "    Inputs:\n",
    "        res_info: a list of dictionaries containing user information\n",
    "    Outputs:\n",
    "        res_text_dict: a dict of user comment\n",
    "    \"\"\"\n",
    "    \n",
    "    res_text_dict = {}\n",
    "\n",
    "    for idx, user in enumerate(res_info):\n",
    "        user_comment = user[\"text\"]\n",
    "        name = \"user{}\".format(idx + 1)\n",
    "        res_text_dict[name] = user_comment\n",
    "    \n",
    "    return res_text_dict\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize the text\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    punctuations = string.punctuation\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    extra_stop_words = set([\"'s\", \"...\", \"'ve\", \"n't\", \"'t\", \"'d\",\"'ll\",\n",
    "                           \"'re\", \"....\"])\n",
    "    stop_words.update(extra_stop_words)\n",
    "    new_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if (token not in punctuations) and (token.lower() not in stop_words)\\\n",
    "            and (re.match(r\"\\d+\", token) == None):\n",
    "                new_tokens.append(token.lower())\n",
    "    \n",
    "    return new_tokens\n",
    "\n",
    "\n",
    "def review_cleaner(review_dta):\n",
    "    \"\"\"\n",
    "    Clean the review data\n",
    "    \n",
    "    Inputs:\n",
    "        review_dta: a dict of review of the restaurants\n",
    "    Outputs:\n",
    "        new_dta: cleaned new data\n",
    "    \"\"\"\n",
    "    \n",
    "    new_dta = dict()\n",
    "    \n",
    "    for restaurant, res_info in review_dta.items():\n",
    "        # Add text into dict\n",
    "        res_dict = dict()\n",
    "        res_dict[\"information\"] = gene_text_dict(res_info)\n",
    "        \n",
    "        # Tokenize the text \n",
    "        tokens_lst = []\n",
    "        for user, text in res_dict[\"information\"].items():\n",
    "            tokens_lst.extend(tokenize(text))\n",
    "        res_dict[\"tokens\"] = tokens_lst\n",
    "        \n",
    "        new_dta[restaurant] = res_dict\n",
    "        \n",
    "    return new_dta\n",
    "\n",
    "\n",
    "def export_to_json(review_dta, filename):\n",
    "    \"\"\"\n",
    "    Export the cleaned review data as json format\n",
    "    \n",
    "    Input:\n",
    "        review_dta: a dictionary containing the cleaned review data\n",
    "        filename(str): filename of the output json file\n",
    "    \"\"\"\n",
    "    address = 'yelp_dataset/cleaned_data'\n",
    "    os.makedirs(address, exist_ok=True)\n",
    "    file_path = address + \"/\" + filename\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(review_dta, f)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    address = \"yelp_dataset/uncleaned_yelp_reviews_new.json\"\n",
    "    review_dta = read_review_json(address)\n",
    "    cleaned_new_dta = review_cleaner(review_dta)\n",
    "    filename = \"cleaned_review_V2.json\"\n",
    "    export_to_json(cleaned_new_dta, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0225080c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
